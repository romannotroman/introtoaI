{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Into to Artificial Intelligence for non tech people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "img { \n",
    "  width:  400px; \n",
    "  display: block;\n",
    "}\n",
    "</style>\n",
    "### Todo\n",
    "\n",
    "- Create a method for doing a research.\n",
    "- Do a research on \"Basics\". How to explain A.I?\n",
    "- Do a research on \"Current developments\". \n",
    "    - Cases and what is approaches currently used to solve real world problems.\n",
    "- Do a research on \"Implication and impact\". Cases:\n",
    "    - Automation\n",
    "    - Government, regulation, policy\n",
    "    - Law\n",
    "    - Ethics\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for doing a research\n",
    "\n",
    "Materials wich we will be dealing:\n",
    "- Articles\n",
    "- Videos\n",
    "- Slides\n",
    "- Images\n",
    "\n",
    "What is the best way not to get bogged down in piles of materials and be able extract what I need withing a meaningful amount of time?\n",
    "\n",
    "1. Limit amout of information.\n",
    "2. Have a plan. List of key concepts and ideas needed to be researched.\n",
    "3. Use quotation tool.\n",
    "4. Briefly scan material. Annotate where possible.\n",
    "5. Do not proccess more that one article in the same time.\n",
    "6. Download images and screenshoots into the images folder.\n",
    "7. Be mindful of materials which you're processing, skip it if it don't informative, too abstract or too difficult to process. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "1. Intro and history.\n",
    "2. Basics. Framework for understanding A.I. \n",
    "3. Current developments in the field and applications. \n",
    "4. Implications and impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key concepts\n",
    "\n",
    "\n",
    "- Artificial Intelligence. Narrow and General Artificial Intelligence\n",
    "- Artificial Neuron and Neural Nets\n",
    "- Data representation\n",
    "- Universal Approximator\n",
    "- Machine Learning\n",
    "- Supervised and Unsupervised Learning\n",
    "- Reiforcement Learning\n",
    "- Deep Learning\n",
    "- ? Transfer Learning\n",
    "\n",
    "### General concepts:\n",
    "- Arfiticial Intelligence Winter\n",
    "- AI-First World\n",
    "- Software 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes and links:\n",
    "\n",
    "- AI Timeline http://www.bbc.co.uk/timelines/zq376fr\n",
    "- https://medium.com/mit-initiative-on-the-digital-economy/ai-and-machine-learning-disruption-timeline-ab589b873dfc\n",
    "- EFF AI progress https://www.eff.org/ai/metrics\n",
    "- Worlds fastest supercomputers https://www.wikiwand.com/en/TOP500\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Into and history\n",
    "1. AI is everywhere\n",
    "2. How humans came to think about intelligent machines.\n",
    "3. Birthday of AI. Alan Turning.\n",
    "4. Maturity.\n",
    "5. The Rise of AI in the Modern World."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI is everywhere.\n",
    "<a id=\"#AI-is-severywhere\"></a>\n",
    "\n",
    "AI has made an incredible progress in past few years: from semi autonomous Telsa cars to Alpha Zero (ancient game Go and Chess).  \n",
    "- It moved to spotlight from academics journals: \"we’ve watched AI move into the spotlight.\"\n",
    "- Number of researh publications has grows exponentially:\n",
    "![papers_by_year.png](images/papers_by_year.png)\n",
    "- Some researchers become like superstars \n",
    "- But only some truly undertand how it works, it's limitations and potential.\n",
    "- People more often operate by myths and fears rather then understanding this technology.\n",
    "\n",
    "**So aim of this presentation is to provide some framework for understanding AI.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defitition of Artificial Intelligence\n",
    "\n",
    "<br/>\n",
    "**Artificial intelligence** involves a machine that exhibits any of the characteristics of learning, perceiving, and using the knowledge they’ve gathered toward a useful and intentional application.\n",
    "\n",
    "The term **\"artificial intelligence\"** is applied when a machine mimics **\"cognitive\" functions** that humans associate with other human minds, such as \"learning\" and \"problem solving.\n",
    "\n",
    "![ai.png](images/ai.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrow, General and Super\n",
    "\n",
    "While there are many different types or forms of AI since AI is a broad concept, there are the critical categories we need to think about:\n",
    "\n",
    "1. **Artificial Narrow (Weak) Intelligence**. Machine intelligence that equals or exceeds human intelligence at specific task. Recognizing images for example.\n",
    "\n",
    "2. **Aftificial General Intelligence**. An agent with the ability to apply intelligence to any problem, rather than one specific problem. \n",
    "\n",
    "3. **Artificial Superintelligence**. An intellect that is much smarter than the best human brains in particulary every field, including scientific creativity, general wisdom and social skills.\n",
    "\n",
    "![superintelligence.png](images/superintelligence.png)\n",
    "\n",
    "\n",
    "But before moving forward lets explore how even people started to think about intelligent agents (machines)?\n",
    "\n",
    "Turns out that almost for entire history people were trying to undetstand intelligence and we dreaming about making intelligent machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History\n",
    "### Myths, automatons and fiction \n",
    "\n",
    "First early mention of intelligent artificial beings could be traced back to **Greek myths**:\n",
    "- Golden and silver lions of Hephaestus\n",
    "- Pygmalion's statue Galatea whom he felt in love with\n",
    "\n",
    "In the **Middle Ages**, there were rumors of secret mystical or alchemical means of placing mind into matter. Such as Rabbi Judah Loew's Golem:\n",
    "\n",
    "![golem_rabbi.jpg](images/golem_rabbi.jpg)\n",
    "\n",
    "\n",
    "Then there was **automatons** realistic humanoid built by **craftsman**. Some believed that craftsman had imbued these figures with very real minds, capable of wisdom and emotion.\n",
    "\n",
    "<center>In 1206 A.D., **Al-Jazari, an Arab inventor**, designed what is believed to be the first programmable humanoid robot, a boat carrying four mechanical musicians powered by water flow:</center>\n",
    "![al_jazari_boat_robot.jpg](images/al_jazari_boat_robot.jpg)\n",
    "<center>**Da Vinci's** walking lion</center>\n",
    "![da_vinchi_lion.gif](images/da_vinchi_lion.gif)\n",
    "<center>**Jaquet-Droz** Automata</center>\n",
    "![jaquet_droz_automata.jpg](images/jaquet_droz_automata.jpg)\n",
    "\n",
    "\n",
    "By the 19th century, ideas about artificial men and thinking machines were developed in fiction, as in **Mary Shelley's Frankenstein** or **Karel Čapek's R.U.R.** (Rossum's Universal Robots).\n",
    "\n",
    "![frankenstein.jpg](images/frankenstein.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formal reasoning\n",
    "\n",
    "**But in order to build intelligent machines first we need to understand intelligence, so different disciplines which were developed in order to explore idea, that human thought can be mechanized.** \n",
    "\n",
    "- The study of mechanical - or \"formal\" - reasoning has a long history. Chinese, Indian and Greek philosophers all developed structured methods of formal deduction in the first millennium BCE. \n",
    "- Their ideas were developed over the centuries by philosophers such as **Aristotle** (who gave a formal analysis of the syllogism (теория логического вывода)), **Euclid** (whose Elements was a model of formal reasoning), **al-Khwārizmī** (who developed algebra and gave his name to \"algorithm\").\n",
    "\n",
    "- In the 17th century, Leibniz, Thomas Hobbes and René Descartes explored the possibility that all rational thought could be made as systematic as algebra or geometry. \n",
    "- Leibniz envisioned a **universal language of reasoning** (his characteristica universalis) which would reduce argumentation to calculation.\n",
    "- These philosophers had begun to articulate the **physical symbol system hypothesis** that would become the guiding faith of AI research:\n",
    "    - \"A physical symbol system has the necessary and sufficient means for general intelligent action.\"\n",
    "    - \"Физическая символьная система имеет необходимые и достаточные средства для произведения базовых интеллектуальных действий, в широком смысле.\"\n",
    "\n",
    "- In the 20th century, the study of mathematical logic provided the essential breakthrough that made artificial intelligence seem plausible. The foundations had been set by such works as Boole's The Laws of Thought and Frege's Begriffsschrift. \n",
    "- Russell and Whitehead presented a **formal treatment of the foundations of mathematics** in their masterpiece, the Principia Mathematica in 1913.\n",
    "- David Hilbert challenged mathematicians of the 1920s and 30s to answer this fundamental question: \"can all of mathematical reasoning be formalized?\n",
    "- His question was answered by Gödel's incompleteness proof, Turing's machine and Church's Lambda calculus.\n",
    "- The Church-Turing thesis implied that a mechanical device, shuffling symbols as simple as 0 and 1, could imitate any conceivable process of mathematical deduction. \n",
    "- The key insight was the **Turing machine** — a simple theoretical construct that captured the essence of **abstract symbol manipulation**. This invention would inspire a handful of scientists to begin discussing the possibility of thinking machines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computer Science\n",
    "\n",
    "- Calculating machines were built in antiquity and improved throughout history by many mathematicians.\n",
    "    - Machines built by Ramon Llul, Pascal and Leibniz\n",
    "- In the early 19th century, Charles Babbage designed a programmable computer (the Analytical Engine), although it was never built.\n",
    "- First algorhitm was written by Ada Loverlace (the only legitimate child of Lord Byron) it was set of instruction for Analytical Engine for calculating a sequence of Bernoulli numbers, which could have run correctly had Babbage's Analytical Engine been built.\n",
    "- The first modern computers were the massive code breaking machines of the Second World War (such as Z3, ENIAC and Colossus). The latter two of these machines were based on the theoretical foundation laid by Alan Turing and developed by John von Neumann.\n",
    "\n",
    "<center>Z3</center>\n",
    "![z3.JPG](images/z3.JPG)\n",
    "<center>ENIAC</center>\n",
    "![eniac.jpg](images/eniac.jpg)\n",
    "<center>Colossus</center>\n",
    "![colossus.png](images/colossus.png)\n",
    "\n",
    " \n",
    "#### The birth of Artificial Intelligence\n",
    " \n",
    "The earliest research into thinking machines was inspired by a confluence of ideas that became prevalent in the late 30s, 40s and early 50s:\n",
    "- Research in neurology had shown that the brain was an electrical network of neurons that fired in all-or-nothing pulses.\n",
    "- Claude Shannon's invented bit and laid foudation of information theory.\n",
    "- Alan Turing's theory of computation showed that any form of computation could be described digitally.\n",
    "\n",
    "**Close relationship between these ideas suggested that it might be possible to construct artificial brain.**\n",
    "\n",
    "In 1951 **Marvin Minsky with Dean Edmonds** built the first neural net machine, the SNARC. Minsky was to become one of the most important leaders and innovators in AI for the next 50 years.\n",
    "\n",
    "###### Dartmouth Conference 1956: the birth of AI\n",
    "\n",
    "The Dartmouth Summer Research Project on Artificial Intelligence was the name of a 1956 summer workshop now considered by many to be the seminal event for artificial intelligence as a field.\n",
    "\n",
    "The Proposal states: \n",
    "\"The study is to proceed on the basis of the **conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves**. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.\"\n",
    "\n",
    "\"Lets see if we can program computers to do sophisticated mental task that people can do. So lets see if we can teach computers to:\"\n",
    "1. **Reason**. E.g. play chess, solve algebra problems... Reasoning task where you presented with problem and you're reasoning your way to answer.\n",
    "2. **Knowledege representation**. Represent knowledge about real world. E.g. what are objects, people, what's language? \n",
    "3. **Planning and navigation**. How to plan and navigate. How do we get from place A to place B? What paths are? \n",
    "4. **Natural Language Processing**. How to speak language, how to understand language, how to create a sentences, how to understand context?\n",
    "5. **Perception**. How do we hear, see, feel things in the world?\n",
    "6. **Generalized Intelligence** (including creativity, moral reasoning, emotional intelligence...). Hope was if we can teach computers all of these discrete parts of human intelligence than the sort of generalized intelligence will emerge and we will get to fully autonomous, thinking, interacting robot. That's was the goal.\n",
    "\n",
    "<center>John McCarthy, author of the term \"artificial intelligence\"</center>\n",
    "![john_mccarthy.jpg](images/john_mccarthy.jpg)\n",
    "<center>Trenchard More, John McCarthy, Marvin Minsky, Oliver Selfridge, and Ray Solomonoff at Darthmouth in 2006</center>\n",
    "![darthmouth_50.jpg](images/darthmouth_50.jpg)\n",
    "\n",
    "\n",
    "\n",
    "Precedesorse for AI winter: optimism\n",
    "\n",
    "##### AI Winters \n",
    "\n",
    "In the 70s, AI was subject to critiques and financial setbacks. AI researchers had failed to appreciate the difficulty of the problems they faced. Their tremendous optimism had raised expectations impossibly high, and when the promised results failed to materialize, funding for AI disappeared.\n",
    "\n",
    "\n",
    "- Perceptron\n",
    "    - A perceptron was a form of neural network introduced in 1958 by Frank Rosenblatt,\n",
    "    - Like most AI researchers, he was optimistic about their power, predicting that \"perceptron may eventually be able to learn, make decisions, and translate languages.\" An active research program into the paradigm was carried out throughout the 60s but came to a sudden halt with the publication of Minsky and Papert's 1969 book Perceptrons.\n",
    "- Minsky mistake in Perceptron and shift from Neural Nets. \n",
    "    - But perceptron models were made very unpopular by the book Perceptrons by Marvin Minsky and Seymour Papert, published in 1969. It demonstrated the limits on the sorts of functions that single-layered (no hidden layer) perceptrons can calculate, showing that even simple functions like the exclusive disjunction (XOR) could not be handled properly.\n",
    "    - Eventually, a new generation of researchers would revive the field and thereafter it would become a vital and useful part of artificial intelligence. Rosenblatt would not live to see this, as he died in a boating accident shortly after the book was published.\n",
    "- Connectionism vs. computationalism \n",
    "    - Connectionism is a set of approaches in the fields of artificial intelligence that **models mental or behavioral phenomena as the emergent processes of interconnected networks of simple units (neurons and neural nets).**\n",
    "    - Computationalism is a specific form of cognitivism that argues that mental activity is computational, that is, that the **mind operates by performing purely formal operations on symbols**, like a Turing machine. Some researchers argued that the trend in connectionism represented a reversion toward associationism and the abandonment of the idea of a language of thought, something they saw as mistaken.\n",
    "    - In 2014, Alex Graves from Deepmind published a series of papers describing a novel Deep Neural Network structure called Neural Turing Machine able to read symbols on a tape and store symbols in memory. Relational Networks, another Deep Network module published by Deepmind are able to create object-like representations and manipulate them to answer complex questions. Relational Networks and Neural Turing Machines are yet another evidence that connectionism and computationalism need not be at odds.\n",
    "    \n",
    "    \n",
    "##### Boom 1980–1987. Expert systems.\n",
    "\n",
    "An **expert system** is a program that answers questions or solves problems about a specific domain of knowledge, using logical rules that are derived from the knowledge of experts. \n",
    "- Expert systems restricted themselves to a small domain of specific knowledge (thus avoiding the commonsense knowledge problem) and their simple design made it relatively easy for programs to be built and then modified once they were in place.\n",
    "- Corporations around the world began to develop and deploy expert systems and by 1985 they were spending over a billion dollars on AI, most of it to in-house AI departments.\n",
    "\n",
    "\"The great lesson from the 1970s was that intelligent behavior depended very much on dealing with knowledge, sometimes quite detailed knowledge, of a domain where a given task lay.\"\n",
    "Knowledge based systems and knowledge engineering became a major focus of AI research in the 1980s.\n",
    "\n",
    "##### The revival of connectionism\n",
    "- In 1982, physicist John Hopfield was able to prove that a form of neural network (now called a \"Hopfield net\") could learn and process information in a completely new way. \n",
    "- Around the same time, David Rumelhart popularized a new method for training neural networks called **\"backpropagation\"** (discovered years earlier by Paul Werbos). \n",
    "- These two discoveries revived the field of connectionism which had been largely abandoned since 1970.\n",
    "\n",
    "\n",
    "##### Bust: the second AI winter 1987–1993\n",
    "\n",
    "Was due to finacial crisis and unmet expectations.\n",
    "\n",
    "**AI winter** is a period of reduced funding and interest in artificial intelligence research.[1] The term was coined by analogy to the idea of a nuclear winter. The field has experienced several hype cycles, followed by disappointment and criticism, followed by funding cuts, followed by renewed interest years or decades later.\n",
    "\n",
    "**Story of AI it's a story about disappointment and revival.**\n",
    "\n",
    "##### AI 1993 – 200s \n",
    "\n",
    "The field of AI, now more than a half a century old, finally achieved some of its oldest goals. It began to be used successfully throughout the technology industry, although somewhat behind the scenes. Some of the success was due to increasing computer power and some was achieved by focusing on specific isolated problems and pursuing them with the highest standards of scientific accountability. Still, the reputation of AI, in the business world at least, was less than pristine.\n",
    "\n",
    "- On 11 May 1997, Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov.\n",
    "- In 2005, a Stanford robot won the DARPA Grand Challenge by driving autonomously for 131 miles along an unrehearsed desert trail.\n",
    "- These successes were not due to some revolutionary new paradigm, but mostly on the tedious application of engineering skill and on the tremendous power of computers today\n",
    "\n",
    "##### \"Victory of the neats\"\n",
    "\n",
    "- Around this time AI researchers began to develop and use sophisticated mathematical tools more than they ever had in the past.\n",
    "- The shared mathematical language allowed both a higher level of collaboration with more established and successful fields and the achievement of results which were measurable and provable; AI had become a more rigorous \"scientific\" discipline.\n",
    "\n",
    "- Judea Pearl's highly influential 1988 book[152] brought probability and decision theory into AI. Among the many new tools in use were **Bayesian networks**, hidden Markov models, information theory, stochastic modeling and classical optimization. \n",
    "- Precise mathematical descriptions were also developed for \"computational intelligence\" paradigms like neural networks and evolutionary algorithms.\n",
    "\n",
    "\n",
    "\n",
    "##### Deep learning, big data and artificial general intelligence: 2000–present\n",
    "\n",
    "In the first decades of the 21st century, access to:\n",
    "- large amounts of data (known as \"big data\"), \n",
    "- faster computers \n",
    "- and advanced machine learning techniques \n",
    "were successfully applied to many problems throughout the economy. \n",
    "\n",
    "By 2016, the market for AI related products, hardware and software reached more than 8 billion dollars.\n",
    "\n",
    "##### Deep learning \n",
    "\n",
    "- Deep learning is a branch of machine learning that models high level abstractions in data by using a deep graph with many processing layers.\n",
    "- Deep learning (also known as deep structured learning or hierarchical learning) is part of a broader family of machine learning methods based on learning data representations, as opposed to task-specific algorithms. Learning can be supervised, semi-supervised or unsupervised.\n",
    "    - use a cascade of multiple layers of nonlinear processing units for feature extraction and transformation. Each successive layer uses the output from the previous layer as input.\n",
    "    - learn in supervised (e.g., classification) and/or unsupervised (e.g., pattern analysis) manners.\n",
    "    - **learn multiple levels of representations that correspond to different levels of abstraction;** the levels form a hierarchy of concepts.\n",
    "    - use some form of gradient descent for training via backpropagation.\n",
    "\n",
    "- According to the Universal approximation theorem, deep-ness isn't necessary for a neural network to be able to approximate arbitrary continuous functions. \n",
    "- Even so, there are many problems that are common to shallow networks (such as **overfitting**) that deep networks help avoid.\n",
    "- As such, deep neural networks are able to realistically generate much more complex models as compared to their shallow counterparts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics. Framework for understanding AI.\n",
    "\n",
    "1. Data.\n",
    "2. Learning representation of data.\n",
    "3. Artificial Neuron. Neural Nets.\n",
    "4. Universal approximation.\n",
    "\n",
    "\n",
    "\n",
    "### Universal appeoximation \n",
    "- One of the most striking facts about neural networks is that they can compute any function at all.\n",
    "- No matter what the function, there is guaranteed to be a neural network so that for every possible input, xx, the value f(x) (or some close approximation) is output from the network.\n",
    "- Neural networks have a kind of universality. No matter what function we want to compute, we know that there is a neural network which can do the job.\n",
    "\n",
    "#### Questions\n",
    "\n",
    "- How artificial neuron works?\n",
    "- \n",
    "\n",
    "#### Links\n",
    "\n",
    "\n",
    "- Use this example, understand it. A16Z primer on AI. Demo with Tensor Flow https://vimeo.com/170189199#t=1632s\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
